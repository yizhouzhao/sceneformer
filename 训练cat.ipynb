{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ca91eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b449fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "# from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37de5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from torchvision.transforms import Compose\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28dde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms.scene import (\n",
    "    SeqToTensor,\n",
    "    Augment_rotation,\n",
    "    Augment_jitterring,\n",
    "    Get_cat_shift_info,\n",
    "    Padding_joint,\n",
    "    Add_Relations,\n",
    "    Add_Descriptions,\n",
    "    Add_Glove_Embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f315920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.suncg_shift_seperate_dataset_deepsynth import SUNCG_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923c9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from separate_models.scene_shift_cat import scene_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c9852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import read_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cbd2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"cfg_path\", help=\"Path to config file\", default=\"configs/scene_shift_cat_config.yaml\")\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02907e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.cfg_path = \"configs/scene_shift_cat_config.yaml\"\n",
    "cfg = read_config(args.cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19a3bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'data_path': '/shared/data/new_room_data/bedroom_new_multi_img',\n",
       "  'out_path': 'tests/data/scene_outputs',\n",
       "  'list_path': 'None'},\n",
       " 'model': {'cat': {'shuffle': False,\n",
       "   'shape_cond': True,\n",
       "   'text_cond': False,\n",
       "   'start_token': 52,\n",
       "   'stop_token': 51,\n",
       "   'pad_token': 50},\n",
       "  'coor': {'shape_cond': True,\n",
       "   'text_cond': False,\n",
       "   'start_token': 203,\n",
       "   'stop_token': 202,\n",
       "   'pad_token': 201},\n",
       "  'orient': {'shape_cond': True,\n",
       "   'text_cond': False,\n",
       "   'start_token': 363,\n",
       "   'stop_token': 362,\n",
       "   'pad_token': 361},\n",
       "  'relation': {'start_token': 4, 'stop_token': 3, 'pad_token': 2},\n",
       "  'dim': {'shape_cond': True,\n",
       "   'start_token': 83,\n",
       "   'stop_token': 82,\n",
       "   'pad_token': 81},\n",
       "  'max_seq_len': 40,\n",
       "  'max_obj_num': 100,\n",
       "  'cat_num': 28,\n",
       "  'emb_dim': 256,\n",
       "  'dim_fwd': 256,\n",
       "  'num_heads': 8,\n",
       "  'num_blocks': 8,\n",
       "  'dropout': 0.3},\n",
       " 'text_model': {'max_seq_len': 100,\n",
       "  'num_heads': 16,\n",
       "  'num_blocks': 6,\n",
       "  'dropout': 0.3,\n",
       "  'voc': 120,\n",
       "  'pad_token': 0},\n",
       " 'train': {'aug': {'jitter_list': [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
       "   'rotation_list': [0, 30, 60, 90, 120, 150, 180, 210, 240, 270]},\n",
       "  'batch_size': 64,\n",
       "  'epochs': 2000,\n",
       "  'lr': 0.0003,\n",
       "  'resume': None,\n",
       "  'total_len': 1200,\n",
       "  'train_len': 1000,\n",
       "  'l2': 0.001,\n",
       "  'lr_restart': 30000,\n",
       "  'warmup': 5000},\n",
       " 'test': {'num_samples': 2,\n",
       "  'probabilistic': False,\n",
       "  'model_file': None,\n",
       "  'log_dir': 'lightning_logs/version_20/out/'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086ed0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['data']['data_path'] = \"/home/ubuntu/research/suncg/bedroom\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e0a93",
   "metadata": {},
   "source": [
    "# run_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9aa22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [Augment_rotation(cfg['train']['aug']['rotation_list']), Augment_jitterring(cfg['train']['aug']['jitter_list']), Get_cat_shift_info(cfg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "215dadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"model\"][\"cat\"][\"text_cond\"]:\n",
    "    transforms += [\n",
    "        Add_Relations(),\n",
    "        Add_Descriptions(),\n",
    "        Add_Glove_Embeddings(max_sentences=3, max_length=50),\n",
    "    ]\n",
    "transforms.append(Padding_joint(cfg))\n",
    "transforms.append(SeqToTensor())\n",
    "t = Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c72ae99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_set = SUNCG_Dataset(data_folder=cfg['data']['data_path'], list_path=cfg['data']['list_path'], transform=t)\n",
    "total_len = len(trainval_set)-2\n",
    "train_len = int(0.8 * total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3761ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Subset(trainval_set, range(train_len))\n",
    "val_set = Subset(trainval_set, range(train_len, total_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef06054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([52,  4,  0,  0,  1,  3,  8, 10, 11, 51, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "         50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "         50, 50, 50, 50]),\n",
       " tensor([203, 150,  50,  28, 109,  55, 154, 126,  55, 202, 201, 201, 201, 201,\n",
       "         201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "         201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201]),\n",
       " tensor([203,  56,  57,  57,  57,  57,  57,  57,  57, 202, 201, 201, 201, 201,\n",
       "         201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "         201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201]),\n",
       " tensor([203, 114,  75, 114, 166, 103,  69, 140,  67, 202, 201, 201, 201, 201,\n",
       "         201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "         201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201]),\n",
       " tensor([363,  60, 240, 240,  60, 240, 150,  60,  60, 362, 361, 361, 361, 361,\n",
       "         361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361,\n",
       "         361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361]),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ede0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=cfg[\"train\"][\"batch_size\"], shuffle=True, num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=cfg[\"train\"][\"batch_size\"], num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d259971d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08e12184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 40])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58a8b286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using shape conditioned model\n"
     ]
    }
   ],
   "source": [
    "model = scene_transformer(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f4ac8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "697ffffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=model.cfg[\"train\"][\"lr\"],\n",
    "            weight_decay= model.cfg[\"train\"][\"l2\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72c74fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.149105548858643\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    cat_seq, x_loc_seq, y_loc_seq, z_loc_seq, orient_seq, room_shape = batch\n",
    "    cat_seq = cat_seq.to(torch.device(\"cuda:0\"))\n",
    "    x_loc_seq = x_loc_seq.to(torch.device(\"cuda:0\"))\n",
    "    y_loc_seq = y_loc_seq.to(torch.device(\"cuda:0\"))\n",
    "    z_loc_seq = z_loc_seq.to(torch.device(\"cuda:0\"))\n",
    "    orient_seq = orient_seq.to(torch.device(\"cuda:0\"))\n",
    "    room_shape = room_shape.to(torch.device(\"cuda:0\"))\n",
    "    \n",
    "    logprobs_cat = model(cat_seq, x_loc_seq, y_loc_seq, z_loc_seq, orient_seq, room_shape=room_shape)\n",
    "    loss_cat = F.nll_loss(\n",
    "        logprobs_cat.transpose(1, 2),\n",
    "        cat_seq[:, 1:],\n",
    "        ignore_index=model.cfg[\"model\"][\"cat\"][\"pad_token\"],\n",
    "    )\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_cat.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"loss: \", loss_cat.item())\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa9291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_ll)",
   "language": "python",
   "name": "conda_ll"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
